---
title : CULane Datasetì„ í™œìš©í•œ UFLD Dataset êµ¬ì„±í•˜ê¸°
date : '2025-03-20'
categories : [Deep Learning]
tags : [culane, ufld, lane detection, dataset, deep learning]
image: assets/img/culane06.png 
---

ì´ í˜ì´ì§€ì—ì„œëŠ” **UFLD (Ultra Fast Lane Detection)**ì™€ í•¨ê»˜ **CULane Dataset**ì„ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ì§€ ì‚´í´ë³´ê² ë‹¤. 
ì²˜ìŒì—” ì–´ë µê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆì–´ë„ ì–´ë ¤ìš´ê²Œ ì•„ë‹ˆë¼ ìµìˆ™í•˜ì§€ ì•Šì•„ì„œ ê·¸ëŸ¬ë‹ˆ, ì—¬ëŸ¬ë²ˆ í•´ë³´ê³  ìµìˆ™í•´ì§€ëŠ” ê²ƒì„ ëª©í‘œë¡œ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•´ë³´ì!

í¬ìŠ¤íŠ¸ ë§ˆì§€ë§‰ì—ëŠ” ê°„ë‹¨í•œ ë¬¸ì œë¥¼ í†µí•´ ë³µìŠµí•  ìˆ˜ ìˆë„ë¡ í•´ë†“ì•˜ë‹¤. ê³„ì† ë³´ë©´ì„œ ìµìˆ™í•´ì ¸ë³´ì!

![Forget Not](assets/img/forget.jpg)
*ë¬¸ì œ í’€ì´ë¥¼ í†µí•´ ìŠì§€ ì•Šê³  ê¾¸ì¤€íˆ ë³µìŠµí•˜ë„ë¡ í•˜ì.*

---

## UFLD & CULane Dataset ì†Œê°œ

UFLDëŠ” lane detection ë„¤íŠ¸ì›Œí¬ ì¤‘ í•˜ë‚˜ë¡œ, ê¸°ì¡´ì˜ segmentation ë°©ì‹ì´ ì•„ë‹Œ **anchor-based** ë°©ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. ë³¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” íŠ¹íˆ **CULane Dataset**ì„ í™œìš©í•˜ì—¬ UFLDì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤. íŠ¹íˆ segmentation ë°ì´í„°ì…‹ì„ anchor ê¸°ë°˜ lane detectionì— ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³¸ë‹¤.

---

## CULane Dataset Investigation

ë¨¼ì €, CULane Datasetì— ëŒ€í•´ ê°„ëµíˆ ì‚´í´ë³´ì.

- **ë°ì´í„° ì¶œì²˜:**  
  ë³¸ ë°ì´í„°ì…‹ì€ Beijingì—ì„œ ë‹¤ì–‘í•œ ìš´ì „ìë“¤ì´ ìš´ì „í•˜ëŠ” 6ëŒ€ì˜ ì°¨ëŸ‰ì„ ì´¬ì˜í•œ ë°ì´í„°ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ìì„¸í•œ ì„¤ëª…ì€ [ê³µì‹ ë¬¸ì„œ](https://xingangpan.github.io/projects/CULane.html)ë¥¼ ì°¸ê³ í•  ìˆ˜ ìˆë‹¤.

- **í´ë” êµ¬ì¡°:**  
  ë°ì´í„°ë¥¼ ì••ì¶• í•´ì œí•˜ë©´ 5ê°œì˜ driving datasetì´ í™•ì¸ë˜ë©°, ì´ ì¤‘ 3ê°œëŠ” **Training & Validation** set, ë‚˜ë¨¸ì§€ 3ê°œëŠ” **Test** setìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.  
  ì˜ˆë¥¼ ë“¤ì–´,  
  - Training & Validation set:  
    - `driver_23_30frame.tar.gz`  
    - `driver_161_90frame.tar.gz`  
    - `driver_182_30frame.tar.gz`
  - Test set:  
    - `driver_37_30frame.tar.gz`  
    - `driver_100_30frame.tar.gz`  
    - `driver_193_90frame.tar.gz`

 ![Dataset Folder Structure](assets/img/culane02.png)*ìœ„ ì´ë¯¸ì§€ëŠ” CULane Datasetì˜ í´ë” êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤€ë‹¤.*

- **Annotation ë°©ì‹:**  
  CULaneì€ **cubic spline**ì„ ì´ìš©í•˜ì—¬ lane markingì„ annotationí•œë‹¤.  
  ì¤‘ìš”í•œ ì ì€ segmentation ë°©ì‹ì´ ì•„ë‹Œ splineì„ í™œìš©í•´ annotationì„ ì§„í–‰í•œë‹¤ëŠ” ê²ƒì´ë‹¤. segmentation ì´ë¯¸ì§€ë„ ìˆì§€ë§Œ ì´ê²ƒì€ splineì„ í™œìš©í•´ ê°€ê³µí•´ì„œ ë§Œë“  GTì¸ ê²ƒì´ë‹¤.
  ë§Œì•½ lane markingì´ ì°¨ëŸ‰ì— ì˜í•´ ê°€ë ¤ì§€ê±°ë‚˜ ëª…í™•í•˜ì§€ ì•Šë”ë¼ë„, ì£¼ë³€ contextë¥¼ ì°¸ê³ í•˜ì—¬ annotationì„ ìˆ˜í–‰í•œë‹¤. ë”°ë¼ì„œ ì´ë¥¼ í™œìš©í•œ ëª¨ë¸ë„ lane predictionì„ í†µí•´ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•˜ê²Œ ëœë‹¤. ì‚¬ì‹¤ segmentation based lane detectionì€ ì´ë ‡ê²Œ ê°€ë ¤ì§„ ë¶€ë¶„ì— ëŒ€í•´ì„œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ì–´ë µì§€ë§Œ UFLDëŠ” lane shapeì— ëŒ€í•œ loss functionì´ ìˆê¸° ë•Œë¬¸ì— occlusionë“±ì˜ ê°€ë ¤ì§„ ë¶€ë¶„ë„ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•´ì§€ëŠ” ê²ƒì´ë‹¤.

- **íŒŒì¼ êµ¬ì„±:**  
  ê° í´ë” ë‚´ì—ëŠ” ì˜ìƒì˜ í”„ë ˆì„ì„ ë‚˜íƒ€ë‚´ëŠ” jpg íŒŒì¼ê³¼ í•´ë‹¹ annotation ì •ë³´ê°€ ë‹´ê¸´ txt íŒŒì¼ì´ ì¡´ì¬í•œë‹¤.  
  ì´ë¯¸ì§€ì˜ í¬ê¸°ëŠ” 1640 x 590ìœ¼ë¡œ, ì˜†ìœ¼ë¡œ ë„“ì€ í˜•íƒœì´ë‹¤.

![Image & Annotation Sample](assets/img/culane03.png)*ê° ì´ë¯¸ì§€ì™€ txt íŒŒì¼ì´ ì–´ë–»ê²Œ ëŒ€ì‘ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.*

- **Annotation Details:**  
  txt íŒŒì¼ì—ëŠ” ìµœëŒ€ 4ê°œì˜ lane markingì— ëŒ€í•´, ê° laneë§ˆë‹¤ ì—¬ëŸ¬ ê°œì˜ **line sampling point** (x, y ì¢Œí‘œ)ê°€ ê¸°ë¡ë˜ì–´ ìˆë‹¤.  
  ì˜ˆë¥¼ ë“¤ì–´, ì•„ë˜ì™€ ê°™ì´ ê°’ë“¤ì´ ë‚˜ì—´ëœë‹¤.

  ```python
  240.573 590 257.848 580 275.127 570 292.409 560 ... 778.228 290
  ```

  ì´ ê°’ë“¤ì€ ì´ë¯¸ì§€ ìƒì—ì„œ ì•„ë˜ì—ì„œ ìœ„ë¡œ, ì¦‰ y ê°’ì´ 10í”½ì…€ì”© ê°ì†Œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ samplingë˜ë©°, ì¼ë¶€ negativeë‚˜ out-of-bound ê°’ì€ laneì„ extendí•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•œë‹¤.  
  ë‹¤ë§Œ UFLDì—ì„œëŠ” ì´ feature pointsë¥¼ ì§ì ‘ í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šê³ , segmentation ground truthë¥¼ ê°€ê³µí•˜ì—¬ anchor ground truthë¥¼ ìƒì„±í•œ í›„ í•™ìŠµì— í™œìš©í•œë‹¤.

- **Additional Annotation Info:**  
  ê° ì´ë¯¸ì§€ì— ëŒ€ì‘ë˜ëŠ” **_gt.txt** íŒŒì¼ì„ í™•ì¸í•˜ë©´, ì´ë¯¸ì§€ ê²½ë¡œ, segmentation label ê²½ë¡œ, ê·¸ë¦¬ê³  ë„¤ ê°œì˜ binary flag (l0â€“l3)ë¥¼ í†µí•´ ê° lane markingì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  
  ì˜ˆë¥¼ ë“¤ì–´,

  ```python
  <image_path> <segmentation_label_path> 1 1 1 1
  ```

  ì´ì™€ ê°™ì´ l0ë¶€í„° l3ê¹Œì§€ ê°ê° 1(ì¡´ì¬) ë˜ëŠ” 0(ë¶€ì¬)ë¡œ í‘œí˜„ëœë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ê´€ë ¨ ë¬¸ì„œ](https://github.com/voldemortX/pytorch-auto-drive/blob/master/docs/datasets/CULANE.md)ë¥¼ ì°¸ê³ í•œë‹¤.

- **Test Split:**  
  test_split í´ë” ë‚´ì—ëŠ” 9ê°œì˜ ì¹´í…Œê³ ë¦¬ë¡œ êµ¬ë¶„ëœ test ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ê°€ ì¡´ì¬í•œë‹¤.  
  ì´ëŠ” ë‚˜ì¤‘ì— ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œ, ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ detectioní•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ metricìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.

  > ![Test Split Categories](assets/img/culane05.png)  
  > *Test splitì— í¬í•¨ëœ 9ê°œì˜ ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ*

- **Visualization:**  
  ì´ë¯¸ì§€ì™€ point-wise annotationì„ ì¤‘ì²©í•˜ì—¬ í™•ì¸í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

  > ![Overlapped Annotation 1](assets/img/culane06.png)  
  > ![Overlapped Annotation 2](assets/img/culane07.png)

<details>
  <summary> visualization code </summary>
  <div markdown="block">
``` python 
# %%
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# %%
DIR = "./culane/driver_161_90frame/06030819_0755.MP4/"
img = plt.imread(DIR+"00000.jpg")
plt.figure(figsize=(16,18))
plt.imshow(img)

# %%
!cat "./culane/driver_161_90frame/06030819_0755.MP4/00000.lines.txt"

# %%
exist_list = []
listfile = DIR + "00000.lines.txt"
with open(listfile) as f:
    for line in f:
        line = line.strip()
        l = line.split(" ")
        exist_list.append([int(eval(x)) for x in l[2:]])

# %%
exist_list[0][0],exist_list[0][1]

# %%
img = img.copy()  # ì´ë¯¸ì§€ ë°°ì—´ì„ writableí•˜ê²Œ ë³µì‚¬

for j in range(len(exist_list)):
    for i in range(0, len(exist_list[j]), 2):
        cv2.circle(img, (exist_list[j][i], exist_list[j][i+1]), radius=0, color=(0, 255, 0), thickness=10)


# %%
plt.figure(figsize=(16,18))
plt.imshow(img)

# %%
mask = plt.imread("./culane/laneseg_label_w16/driver_161_90frame/06030819_0755.MP4/00000.png")
plt.figure(figsize=(16,18))
plt.imshow(mask*255);

# %%
np.unique(mask), np.unique(mask*255)

# %%

```
</div>
</details> 

---

> ì ì´ì œ datasetì„ ë‹¤ìš´ë°›ì•„ë†“ê³  ì´ì œ ë„¤íŠ¸ì›Œí¬ ë§Œë“¤ê¸° ì½”ë”©ì„ í•˜ë ¤í•˜ë‹ˆ ë²Œì¨ ë©í•˜ë‹ˆ ëª¨ë‹ˆí„°ë¥¼ 3ì‹œê°„ ë™ì•ˆ ë°”ë¼ ë³´ê³  ìˆë‹¤. ê·¸ ë’¤ì—ë¼ë„ ì‹œì‘í•˜ë©´ ë‹¤í–‰ì´ë‹¤. ë³´í†µì€ ì €ë…ì‹œê°„ì´ ë˜ì–´ ë‚˜ê°€ ë†€ê³  ì´ í”„ë¡œì íŠ¸ëŠ” í¬ê¸°í•˜ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.

![coding](assets/img/coding.png)  
{: .dark .w-75 .shadow .rounded-10 w='1212' h='668' }
ì´ëŸ° ì•ˆíƒ€ê¹Œìš´ ìƒí™©ì€ ìš°ë¦¬ë„¤ ê°œë°œì¸ìƒì— ê³„ì†í•´ì„œ ìƒê¸´ë‹¤.

ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë°›ê±°ë‚˜ ì œì‘í•œ ë‹¤ìŒì— ìš°ë¦¬ëŠ” ë¬´ì—‡ì„ ì†ëŒ€ì•¼í• ê¹Œ?

ê·¸ ì²« ìŠ¤í…ì€ ë°ì´í„° êº¼ë‚´ê¸° ë†€ì´ë¥¼ í•´ì•¼í•˜ëŠ” ê²ƒì´ë‹¤.

> ë§‰ë§‰í•  ìˆ˜ ìˆë‹¤. ê´œì°®ë‹¤. ê±°ì˜ ì •í•´ì§„ ìˆ˜ìˆœì„ ë°Ÿìœ¼ë©´ ëœë‹¤. ê·¸ë‹¥ ì°½ì˜ì ì¸ ì‘ì—…ë„ ì•„ë‹ˆê³  ë³µì¡í•œ ì‘ì—…ë„ ì•„ë‹ˆë‹¤. í•œë²ˆ ì„¸íŒ…í•´ë†“ìœ¼ë©´ ë³„ë¡œ ê±´ë“¤ì¼ ì¼ë„ ì—†ë‹¤. ê·¸ë˜ data folderë¥¼ ìƒì„±í•˜ì—¬ dataset.pyë¥¼ ì‘ì„±í•´ë³´ì.

## UFLD dataset ì„¤ê³„í•˜ê¸°

ì´ë ‡ê²Œ ìƒê°í•´ë³´ì‹­ì‹œë‹¤.

Datasetê³¼ Dataloader libraryê°€ ì—†ë‹¤ê³  ìƒê°í•´ë´…ì‹œë‹¤.

ì ë°ì´í„°ì…‹ì´ ìˆë‹¤. ê·¸ëŸ¬ë©´ ë°ì´í„°ë¥¼ ì´ í”„ë¡œê·¸ë¨ ë‚´ë¡œ ê°€ì ¸ì™€ì•¼í•œë‹¤.

ê°€ì ¸ì™€ì„œ í•™ìŠµë°ì´í„°ë¡œ ë„£ì–´ì£¼ì–´ì•¼í•œë‹¤. ê·¸ê²ƒë„ batchë¡œ ë„£ì–´ì£¼ì–´ì•¼ í•œë‹¤.

ì´ë¥¼ ì–´ë–»ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆì„ì§€ ìƒê°í•´ë³´ì. ìš°ì„  requirementë¥¼ ì‘ì„±í•´ë³´ëŠ” ê²ƒì´ë‹¤.

Open Datasetì€ ì´ë¯¸ì§€ì™€ ê·¸ì— ëŒ€ì‘í•˜ëŠ” GTê°€ ì—¬ëŸ¬ê°€ì§€ í˜•íƒœë¡œ ë§Œë“¤ì–´ì ¸ìˆì„ ê²ƒì´ë‹¤.

ìš°ë¦¬ê°€ í™œìš©í•  CULane datasetì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ê·¸ ì´ë¯¸ì§€ì™€ GTì˜ ì •ë³´ê°€ ë§¤ì¹­ë˜ì–´ìˆë‹¤.

culane/list/train_gt.txtëŠ” ì´ë ‡ê²Œ ë˜ì–´ìˆë‹¤.

```
/driver_23_30frame/05151649_0422.MP4/00000.jpg /laneseg_label_w16/driver_23_30frame/05151649_0422.MP4/00000.png 1 1 1 1
```

`<img_dir> <seg_dir> l0 l1 l2 l3 existance`

ì´ë ‡ê²Œ ë˜ì–´ìˆë‹¤.

ì ê·¸ëŸ¬ë©´ train_gt.txtì™€ val_gt.txtë¥¼ ì½ì–´ì™€ì•¼í•œë‹¤.

í•œì¤„ì”© ì½ì–´ì•¼ í•œë‹¤.

ê·¸ë¦¬ê³  ê·¸ê²ƒì„ íŒŒì‹±í•´ì„œ ì´ë¯¸ì§€ì™€ annotation íŒŒì¼ì„ ì½ì–´ë“¤ì—¬ì•¼ í•œë‹¤.

ì•„ë§ˆë„ ì´ë¯¸ì§€ëŠ” í…ì„œë¡œ ë§Œë“¤ì–´ì£¼ê±°ë‚˜ resizeí•˜ëŠ” ë“± transformí•´ì•¼í•œë‹¤.

ì´ë•Œì— trainí• ë•Œë‘ val, testí• ë•Œì˜ transformì€ ë‹¬ë¼ì•¼ í•  ê²ƒì´ë‹¤.

annotationë„ ë§ˆì°¬ê°€ì§€ë¡œ í•™ìŠµì— ìš©ì´í•˜ê²Œ preprocessingì„ ì§„í–‰í•˜ì—¬ì•¼ í•œë‹¤.

ê·¸ë ‡ê²Œ ì´ì œ ìš”ì²­ì´ ì˜¬ë•Œë§ˆë‹¤ input dataì™€ annotationì„ êº¼ë‚´ì£¼ì–´ì•¼ í•œë‹¤.

ê·¸ëŸ°ë° í•˜ë‚˜ì”©ì´ ì•„ë‹ˆê³  batchë¡œ êº¼ë‚´ì¤„ ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.

ì´ëŸ° ì—­í• ì„ í•˜ëŠ” classë¥¼ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ê²ƒì´ë‹¤.

> ë‚˜ëŠ” ê°œë°œìë¡œì„œ ë²Œì¨ ì•½ 7ë…„ì§¸, ì„ì‚¬ê¹Œì§€ í•˜ë©´ ê±°ì˜ 10ë…„ì§¸ ê°œë°œë°¥ ë¨¹ê³  ì‚´ê³  ìˆë‹¤. í›„í›„ ì´ì •ë„ requirementëŠ” ì‹ì€ì£½ ë¨¹ê¸°ë¡œ ê¸ˆë°© ë‘ë“œë¦´ ìˆ˜ ìˆë‹¤.

2 hours laterâ€¦

```python
import os
import torch.Dataset as Dataset
import text
import torchvision.Transform as Transform
import PIL
from Transform import ToTensor, Rotate, Resize

class CULaneDataset: public Dataset:
    __init__(self, list_dir, is_train=true):
        self.list_dir = list_dir
        self.is_train = is_train
        self.height = 500
        self.width = 500
        self.train_transform = Transform(ToTensor(), Resize(height, width), Rotate(20))
        self.val_transform = Transform(ToTensor(), Resize(height, width))
    parsingDB()

    parsingDB(self):
        if is_train:
            list_txt_dir = os.path.join(self.list_dir, "train_gt.txt")
            list_txt = text.import(list_txt_dir)
            for i in range(list_txt.size()):
                img_path = list_txt[i][0]
                l0_ex = list_txt[i][2]
                l1_ex = list_txt[i][3]
                l2_ex = list_txt[i][4]
                l3_ex = list_txt[i][5]
                anno_path = list_txt[i][0] - '.jpg' + '.lines.txt'
                img = PIL.Image(img_path)
                input_data = img.train_transform
                # how do I cope with annotation..?

```

![](assets/img/gun_pepe.png) 
*ë‚´ 10ë…„!*

ë‹¤ì‹œ ì°¨ê·¼ì°¨ê·¼ custom datasetì— ëŒ€í•œ ë‚´ìš©ì„ ë³´ì

## Custom Dataset

`torchvision.datasets` ì—ì„œ ì œê³µí•˜ëŠ” datasetë“¤ì€ ëª¨ë‘ pytorchì˜ `Dataset` classë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„ ë˜ì–´ ìˆë‹¤. ë”°ë¼ì„œ ì§ì ‘ custom datasetì„ êµ¬ì„± í•  ë•Œì—ë„ ì´ëŸ¬í•œ `Dataset` ì¸í„°í˜ì´ìŠ¤ë¥¼ ë”°ë¥¼ ìˆ˜ ìˆë‹¤.

---

### Dataset class ì´í•´í•˜ê¸°

`Dataset` classë¥¼ ìƒì†ë°›ì•„ custom datasetì„ ì •ì˜ í•  ë•Œì—ëŠ” ëª‡ê°€ì§€ í•„ìˆ˜ ë©”ì„œë“œë¥¼ êµ¬í˜„í•´ì•¼ í•œë‹¤.

1.  `__init__()`: dataset ê°ì²´ì˜ ì´ˆê¸°í™” method. datasetì˜ ê²½ë¡œë‚˜ transform ë°©ì‹ë“±ì„ ì„¤ì •í•¨
2.  `__len__()`: datasetì˜ í¬ê¸°ë¥¼ ë°˜í™˜í•˜ëŠ” method. ë°ì´í„°ì…‹ì˜ ì´ data ê°œìˆ˜ë¥¼ ë°˜í™˜í•´ì•¼ í•œë‹¤
3.  `__getitem__(idx)`: íŠ¹ì • indexì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ëŠ” method. `idx`ì— í•´ë‹¹í•˜ëŠ” dataë¥¼ ë¶ˆëŸ¬ì™€ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ ë°˜í™˜í•˜ë„ë¡ í•œë‹¤.

ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ufld codeì˜ `dataset.py`ë¥¼ ë¶„ì„í•´ë³´ì.

![](assets/img/ufld_arch.png)
*ufldì˜ architectureëŠ” ìœ„ì™€ ê°™ë‹¤. res blocksê°€ backboneì´ ë˜ê³  auxiliary branchì™€ main branchë¡œ ë‚˜ëˆ„ì–´ì ¸ìˆìœ¼ë©° auxiliary branchëŠ” trainingì‹œì—ë§Œ í™œì„±í™”ë˜ê³ , segmentation labelì„ í†µí•´ í•™ìŠµì´ ì§„í–‰ëœë‹¤.*

`LaneClsDataset`ì—ì„œ clsë‘ seg labelì„ êµ¬í•˜ëŠ”ê²Œ ì¤‘ì ì´ ëœë‹¤ê³  ë³´ë©´ ëœë‹¤.

ì‚¬ì‹¤ìƒ `__getitem__` ì„ ì¤‘ì ìœ¼ë¡œ ë³´ë©´ ëœë‹¤.

imgì™€ label ì´ ìˆëŠ”ë° ì—¬ê¸°ì„œ label pathëŠ” seg label imgë¼ê³  ë³´ë©´ ëœë‹¤.

ê·¸ë¦¬ê³  ëª¨ë‘ì— `simu_transform`ì„ ìš°ì„  ì ìš©í•œë‹¤. ì´ê±°ëŠ” imageì™€ segì— ë‹¤ ì ìš©í•œë‹¤ ë¼ëŠ” ê±°ë¼ê³  ë³´ë©´ ëœë‹¤.

ì‚¬ì‹¤ìƒ point wise gtëŠ” í™œìš©í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

segmapì—ì„œ í•´ë‹¹ laneì— í•´ë‹¹í•˜ëŠ” ê·¸ê±°ê°€ ìˆìœ¼ë©´ rowì˜ í‰ê· ê°’ì„ ë‚´ì–´ì„œ ê·¸ê±°ë¥¼ point wise gtë¼ê³  í•´ì•¼í•˜ë‚˜ row wise gtë¡œ í™œìš©í•˜ê²Œ ëœë‹¤.

`__get_index`ì—ì„œëŠ” extensionë„í•´ì„œ ì–´ì¨Œë“  ê·¸ pointsë“¤ì„ ë½‘ì•„ë‚¸ë‹¤. ê·¸ë¦¬ê³  `cls_label`ì€ `__grid_pts`í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ê·¸ê²Œ ê·¸ëŸ¬ë‹ˆê¹Œ columnìœ¼ë¡œë„ samplingí•´ì„œ ê·¸ ê°œìˆ˜ëŠ” `griding_num`ì¸ë° ì´ê±¸ í†µí•´ì„œ cls labelì„ ë½‘ì•„ë‚¸ë‹¤.

ê·¸ë˜ì„œ img, cls_labelì„ ì•„ì›ƒí’‹ìœ¼ë¡œ ë‚´ê²Œ ëœë‹¤.

ì „ì²´ ì½”ë“œëŠ” ([https://github.com/cfzd/Ultra-Fast-Lane-Detection/blob/master/data/dataset.py](https://github.com/cfzd/Ultra-Fast-Lane-Detection/blob/master/data/dataset.py)) ì—¬ê¸°ì— ìˆê³ , ì½”ë“œ í•˜ë‚˜í•˜ë‚˜ ì¢€ ëœ¯ì–´ë³´ê² ë‹¤.


> ì—­ì‹œë‚˜ ìµìˆ™í•˜ì§€ ì•Šì„ ê²ƒì´ë‹¤. ê·¸ë˜ë„ ë³„ìˆ˜ìˆëŠ”ê°€ ë”¥ëŸ¬ë‹ ê°œë°œìê°€ë˜ë ¤ë©´ í”¼í•  ìˆ˜ ì—†ë‹¤. ë“¤ì´ëŒ€ì•¼í•œë‹¤.
{: .prompt-tip }

`def loader_func(*path*)`: ê°™ì€ common í•¨ìˆ˜ëŠ” ë„˜ì–´ê°€ë„ë¡ í•˜ê² ë‹¤. ì—¬ê¸°ì„œëŠ” `LaneClsDataset` í´ë˜ìŠ¤ì— ëŒ€í•´ì„œë§Œ í™•ì‹¤íˆ ì´í•´í•˜ê³  ë„˜ì–´ê°€ë„ë¡ í•˜ê² ë‹¤.

pytorchì—ì„œ ëª¨ë“  custom datasetì€ `torch.utils.data`ì˜ `Dataset`ì˜ íŒŒìƒí´ë˜ìŠ¤ë¡œ ë§Œë“¤ì–´ì§„ë‹¤.

ìœ„ì—ì„œë„ ì–¸ê¸‰í–ˆë“¯ì´ `__init__`, `__len__`, `__getitem__`ì€ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼í•˜ëŠ” ë©”ì†Œë“œì´ë‹¤.

`__init__`ì˜ êµ¬í˜„ì— ëŒ€í•´ì„œëŠ” ë§ê³ , argumentì— ëŒ€í•´ì„œ ì•Œê³  ë„˜ì–´ê°€ì

```python
    def __init__(self, root_path, list_path, img_transform=None, target_transform=None, simu_transform=None,\
        row_anchor=None, griding_num=50, use_aux=False, segment_transform=None, num_lanes=4):
        super(LaneClsDataset, self).__init__()
        self.root_path = root_path
        self.list_path = list_path
        self.img_transform = img_transform
        self.target_transform = target_transform
        self.simu_transform = simu_transform
        self.segment_transform = segment_transform
        self.row_anchor = row_anchor # ascending order
        self.griding_num = griding_num
        self.use_aux = use_aux
        self.num_lanes = num_lanes
```

---

transformë“¤ì„ ë³´ì.

ufldì—ì„œ ì‚¬ìš©ëœ transformê´€ë ¨ postì—ì„œ ì„¤ëª…í•˜ê² ì§€ë§Œ

ì—¬ê¸°ì„œë„ ê°„ëµí•˜ê²Œ ì„¤ëª…í•˜ìë©´

```python
img_transform = transforms.Compose([
    transforms.Resize((288, 800)),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])
target_transform = transforms.Compose([
    mytransforms.FreeScaleMask((288, 800)),
    mytransforms.MaskToTensor()
])
simu_transform = mytransforms.Compose2([
    mytransforms.RandomRotate(6),
    mytransforms.RandomUDoffsetLABEL(100),
    mytransforms.RandomLROffsetLABEL(200)
])
segment_transform = transforms.Compose([
    mytransforms.FreeScaleMask((100, 200)),
    mytransforms.MaskToTensor()
])
```

ìš°ì„ ì€ `target_transform`ì€ ufld ì½”ë“œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤. ì™œ ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ëŠ” ëª¨ë¥´ê² ìœ¼ë‚˜ `segment_transform`ê³¼ ë§¤ìš° ìœ ì‚¬í•˜ë‹¤. ë‹¤ë¥¸ê²ƒì€ `FreeScaleMask`ë¶€ë¶„ì¸ë° ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì´ mask ì´ë¯¸ì§€ë¥¼ resizeí•˜ëŠ” í´ë˜ìŠ¤ì´ë‹¤.

```python
# FreeScaleMask: ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ sizeë¡œ resizeí•˜ëŠ” í´ë˜ìŠ¤
class FreeScaleMask(object):
    # __init__: target sizeë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    def __init__(self, size):
        self.size = size

    # __call__: ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë¥¼ target sizeë¡œ resize í•©ë‹ˆë‹¤. (Nearest interpolation ì‚¬ìš©)
    def __call__(self, mask):
        return mask.resize((self.size[1], self.size[0]), Image.NEAREST)
```

`segment_transform`ì€ h 100, w 200ìœ¼ë¡œ ë§¤ìš° ì €í™”ì§ˆì¸ë° `target_transform`ì€ ê³ í™”ì§ˆë¡œì„œ ì•„ë§ˆë„ segmentation resolutionì„ ë°”ê¿”ê°€ë©° í•™ìŠµì— í™œìš©í–ˆë˜ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

ë˜ `simu_transform`ì€ simultaneous transformìœ¼ë¡œì„œ ì´ë¯¸ì§€ì™€ labelì— ë™ì¼í•˜ê²Œ ì‚¬ìš©ë˜ì–´ì§€ëŠ” transformì´ë‹¤. random rotateì™€ random ìƒí•˜, ì¢Œìš° shiftê°€ ìˆë‹¤.

ë‹¤ìŒìœ¼ë¡œ

```python
self.row_anchor = [121, 131, 141, 150, 160, 170, 180, 189, 199, 209, 219, 228, 238, 248, 258, 267, 277, 287]
```

ì´ê±°ëŠ” predefinedëœ row_anchorì˜ ìœ„ì¹˜ì •ë³´ì´ë‹¤.

ê¸°ì¤€ì€ heightê°€ 288ì¼ë•Œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ” row anchorì´ê¸° ë•Œë¬¸ì— hê°€ 288ì´ ì•„ë‹ˆë¼ë©´ ë‚˜ì¤‘ì— ë³´ì •í•˜ê²Œ ëœë‹¤.

`griding_num`ì€ gridì˜ columnê°œìˆ˜ì´ë‹¤. ufldì—ì„œëŠ” 200ê°œë¥¼ ì“´ë‹¤.

`use_aux`ëŠ” auxiliaryë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€ì— ëŒ€í•œ ê²ƒì´ë‹¤. ë³´í†µì€ ì‚¬ìš©í•˜ì—¬ segmentationì •ë³´ë„ í•™ìŠµì— í™œìš©í•˜ê²Œ ëœë‹¤.

`num_lanes`ëŠ” ufldì—ì„œëŠ” 4ê°œê°€ ëœë‹¤.

ë‹¤ìŒìœ¼ë¡œëŠ” ëŒ€ë§ì˜ `__getitem__`ë˜ì‹œê² ë‹¤.

ì´ ë©”ì†Œë“œëŠ” í•­ìƒ `idx`ë¥¼ argumentë¡œ ê°€ì ¸ì˜¤ê²Œ ëœë‹¤.

```python
    def __getitem__(self, idx):
        l_info = self.list[idx].split()
        img_path, label_path = l_info[0], l_info[1]
        if os.path.isabs(img_path):
            img_path = img_path[1:]
        if os.path.isabs(label_path):
            label_path = label_path[1:]
        img_name = img_path
        img_path = os.path.join(self.root_path, img_path) # 'culane/driver_23_30frame/05160832_0468.MP4/03015.jpg'
        label_path = os.path.join(self.root_path, label_path) # 'culane/laneseg_label_w16/driver_23_30frame/05160832_0468.MP4/03015.png'

```

ì´ì— ë”°ë¼ ì´ ê²ƒì˜ ì´ë¯¸ì§€ì™€ labelì— ëŒ€í•´ returní•˜ë„ë¡ êµ¬ì„±í•˜ì—¬ì•¼í•œë‹¤.

`l_info`ëŠ” ì´ë ‡ê²Œ êµ¬ì„±ë˜ê²Œ ëœë‹¤.

`['/driver_23_30frame/05160832_0468.MP4/03015.jpg', '/laneseg_label_w16/driver_23_30frame/05160832_0468.MP4/03015.png', '0', '1', '1', '1']`

img path, label path, ë„¤ laneì˜ existance ì •ë³´ê°€ ìˆë‹¤.

`isabs`ëŠ” absolute directoryì¸ì§€ ë¥¼ íŒë‹¨í•˜ëŠ”ê±´ë° ë‘˜ë‹¤ ì•ì—  slashê°€ ìˆì–´ì„œ ì´ê±° `os.path.join`í•˜ê¸°ì „ì— ì§€ì›Œì•¼í•˜ë¯€ë¡œ 1index stringë¶€í„°ë¡œ í•˜ë„ë¡ ë°”ê¾¸ëŠ”ê±°ê³ 

ê·¸ë˜ì„œ `img_path`ì™€ `label_path`ì— ê°ê° pathê°€ mappingë˜ê²Œëœë‹¤.

```python
        img = loader_func(img_path)
        label = loader_func(label_path)

        if self.simu_transform is not None:
            img, label = self.simu_transform(img, label)

```

ì´ê±°ëŠ” PIL Imageë¡œ convertingí•˜ëŠ”ê±°ê³  imageì™€ labelëª¨ë‘ `simu_transform`ì„ ì ìš©í•œë‹¤.

torchvisionì—ì„œëŠ” transformë‹¨ê³„ì—ì„œ tensorë¡œ ë³€í™˜ì „ì— PIL(pillow) Imageë¥¼ ì‚¬ìš©í•œë‹¤.

`simu_transform`ì—ì„œëŠ” `ToTensor`ë¡œ ë³€í™˜í•˜ëŠ”ê²Œ í¬í•¨ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ `img`, `label`ì€ PIL Image í˜•ì‹ì„ ìœ ì§€í•œë‹¤.

ê·¸ ë’¤ê°€

```python
lane_pts = self._get_index(label)
```

`_get_index` ì´ë‹¤. segment labelì„ inputìœ¼ë¡œ ë°›ê²Œ ëœë‹¤.

private methodí˜¹ì€ internal methodë¼ê³  ë¶€ë¥´ëŠ”ë° ì´ classì•ˆì˜ methodì—ì„œë§Œ í˜¸ì¶œí•œë‹¤ëŠ” ëœ»ì´ë‹¤.

```python
    def _get_index(self, label):
        w, h = label.size # 1640, 590

        # if the height is not 288, scale the row_anchor accordingly
        # row_anchor = [121, 131, 141, 150, 160, 170, 180, 189, 199, 209, 219, 228, 238, 248, 258, 267, 277, 287]
        if h != 288:
            row_anchor = [int(x * h / 288) for x in self.row_anchor]
        else:
            row_anchor = self.row_anchor

        # create an array to hold lane coordinates
        all_idx = np.zeros((self.num_lanes, len(row_anchor), 2))
        # all_idx.shape
        # (4, 18, 2)

```

ì´ í•¨ìˆ˜ì—ì„œ ì²«ë¶€ë¶„ì€ segì˜ sizeë¥¼ í™•ì¸í•˜ëŠ” ë¶€ë¶„ì¸ë° 1640, 590ìœ¼ë¡œ ì´ëŠ” `row_anchor`ì˜ ê¸°ì¤€ hì¸ 288ê³¼ ë‹¤ë¥´ê²Œ ë˜ë¯€ë¡œ compensation? interpolation?ì„í•´ì•¼í•œë‹¤.

ê·¸ë˜ì„œ ìµœì¢…ì ìœ¼ë¡œ `row_anchor`ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ëœë‹¤.

```
[247, 268, 288, 307, 327, 348, 368, 387, 407, 428, 448, 467, 487, 508, 528, 546, 567, 587]
```

ì´ë¯¸ì§€ë¥¼ ë´¤ì„ë•Œ ìœ„ì—ì„œ ì•„ë˜ìª½ìœ¼ë¡œ ì •ë ¬ë˜ì–´ìˆë‹¤.

ê·¸ë˜ì„œ ì´í›„ì—ëŠ” ì´ `row_anchor`ë“¤ì„ ëŒë©´ì„œ lineë³„ë¡œ segmentê°€ ì¡´ì¬í•˜ëŠ”ì§€, ì¡´ì¬í•œë‹¤ë©´ ì–´ë””ì— ìœ„ì¹˜í•´ìˆëŠ”ì§€ ê·¸ë¦¬ê³  ê·¸ê²ƒì„ í•˜ë‚˜ì˜ pointë¡œ í™˜ì‚°í•´ì„œ ì €ì¥í•˜ì—¬ ë°˜í™˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ ëŒì•„ê°€ê²Œ ëœë‹¤.

ê·¸ë˜ì„œ `all_idx`ì—ì„œëŠ” (4, 18, 2)ì˜ shapeì„ ê°–ê²Œë˜ê³  ë‘ë²ˆì§¸ dimì—ëŠ” anchorì˜ ìˆœì„œ index 0 to 17ê°€ ì €ì¥ë˜ê³  ë§ˆì§€ë§‰ dimì—ì„œëŠ” row ê°’, x(lateral) ê°’ì´ ì €ì¥ë˜ê²Œ ëœë‹¤.

```python
        # iterate over each row anchor
        for i, row in enumerate(row_anchor):
            # Convert the label to a NumPy array and extract the row at position r.
            label_r = np.asarray(label)[int(round(row))]
            # For each potential lane (lane indices 1 to num_lanes)
            for lane_idx in range(1, self.num_lanes + 1):
                # Find column indices in this row that match the lane ID.
                pos = np.where(label_r == lane_idx)[0]
                if len(pos) == 0:
                    # If no pixels match, record the row number and assign -1 as the column value.
                    all_idx[lane_idx - 1, i, 0] = row
                    all_idx[lane_idx - 1, i, 1] = -1
                    continue
                # Otherwise, compute the average column coordinate.
                pos = np.mean(pos)
                all_idx[lane_idx - 1, i, 0] = row
                all_idx[lane_idx - 1, i, 1] = pos

```

`label`ì€ segmentation labelì´ë‹¤. ì´ë¥¼ `asarray`ë¡œ np arrayë¡œ ë°”ê¿¨ê³  ê±°ê¸°ì— `row`ë²ˆì§¸ëŠ” í•´ë‹¹í•˜ëŠ” widthì— ê°’ì´ ì €ì¥ë˜ì–´ìˆì„ ê²ƒì´ë‹¤.

ê·¸ labelì—ëŠ” 1,2,3,4 ì´ë ‡ê²Œ line indexê°€ mappingë˜ì–´ìˆë‹¤.(0,1,2,3 ì•„ë‹˜ ì£¼ì˜)

line indexì— í•´ë‹¹í•˜ëŠ” ê°’ì´ ì—†ë‹¤ë©´ `pos`ëŠ” lengthê°€ 0ìœ¼ë¡œ ë‚˜ì˜¬ ê²ƒì´ê³ , ìˆë‹¤ë©´

```
pos
array([673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,
       686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698,
       699, 700, 701, 702, 703])
```

ì´ëŸ°ì‹ìœ¼ë¡œ y pointsê°€ arrayë¡œ `pos`ì— ì €ì¥ë˜ì–´ìˆë‹¤.

ê·¸ë˜ì„œ `pos`ê°€ ì—†ë‹¤ë©´ `all_idx`ì˜ ë§ˆì§€ë§‰ elementì— -1ê°€ ë˜ê³  ìˆë‹¤ë©´ `pos`ë¥¼ í‰ê· ì¹œ pointê°€ ì €ì¥ë˜ê²Œ ëœë‹¤.

ë§Œì•½ì— left rightì— ë”°ë¼ì„œ ì•ˆìª½ elementë¡œ í•˜ê³ ì‹¶ë‹¤ë©´ ê·¸ë ‡ê²Œ ì €ì¥ë˜ê²Œ í•´ë„ ëœë‹¤. í•˜ì§€ë§Œ UFLDì—ì„œëŠ” ì¤‘ê°„ê°’ìœ¼ë¡œ pointë¥¼ ë½‘ì•„ë‚´ê²Œ ëœë‹¤.

ê·¸ë˜ì„œ ì˜ˆë¥¼ë“¤ì–´ `all_idx[1]`ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê°’ì´ ì €ì¥ë˜ê²Œ ëœë‹¤.

```
all_idx[1]
array([[247. , 688. ],
       [268. , 658. ],
       [288. , 628.5],
       [307. , 602. ],
       [327. , 572.5],
       [348. , 543. ],
       [368. , 514. ],
       [387. , 487. ],
       [407. , 457.5],
       [428. , 428. ],
       [448. , 398.5],
       [467. , 371. ],
       [487. , 344.5],
       [508. ,  -1. ],
       [528. ,  -1. ],
       [546. ,  -1. ],
       [567. ,  -1. ],
       [587. ,  -1. ]])
```

ì—¬ê¸°ì„œ ì´ì œ ëë‚¼ìˆ˜ë„ ìˆì§€ë§Œ transformì„ í†µí•´ì„œ rotationí•˜ê±°ë‚˜ í•˜ë©´ bottomìª½ì—ëŠ” labelì´ ì—†ì–´ì§€ê²Œ ë˜ê³ , ì´ë¥¼ ë³´ì™„í•´ì£¼ê¸° ìœ„í•´ì„œ ì•„ë˜ìª½ì— polynomial fittingí•´ì„œ linear extrapolationí•˜ê²Œ ëœë‹¤.

```python
        all_idx_cp = all_idx.copy()
        for i in range(self.num_lanes):
            if np.all(all_idx[i, :, 1] == -1):
                continue
            valid = all_idx_cp[i, :, 1] != -1
            valid_idx = all_idx_cp[i, valid, :]
            if valid_idx[-1, 0] == all_idx_cp[0, -1, 0]:
                continue
            if len(valid_idx) < 6:
                continue
            valid_idx_half = valid_idx[len(valid_idx)//2:, :] # take the bottom half of the valid indices
            p = np.polyfit(valid_idx_half[:, 0], valid_idx_half[:, 1], deg=1)
            start_line = valid_idx_half[-1, 0] # the bottom line of the valid row == valid_idx[-1, 0]
            pos = find_start_pos(all_idx_cp[i, :, 0], start_line) + 1 # right after valid most bottom idx

            fitted = np.polyval(p, all_idx_cp[i, pos:, 0])
            fitted = np.array([-1 if y < 0 or y > w - 1 else y for y in fitted])
            assert np.all(all_idx_cp[i, pos:, 1] == -1)
            all_idx_cp[i, pos:, 1] = fitted

        # if any row coordinate is unexpectedly -1, trigger debugging.
        if -1 in all_idx[:,:,0]:
            pdb.set_trace()
        return all_idx_cp

```

ì´ë¶€ë¶„ì€ í•µì‹¬ì ì¸ ë¶€ë¶„ì€ ì•„ë‹ˆë‹ˆ passí•˜ê² ë‹¤.

ì´ì œ extrapolationê¹Œì§€ ëœ lane gt pointsë“¤ì´ ì–»ì–´ì§€ê²Œ ëœë‹¤

```
lane_pts[1]
array([[247.        , 688.        ],
       [268.        , 658.        ],
       [288.        , 628.5       ],
       [307.        , 602.        ],
       [327.        , 572.5       ],
       [348.        , 543.        ],
       [368.        , 514.        ],
       [387.        , 487.        ],
       [407.        , 457.5       ],
       [428.        , 428.        ],
       [448.        , 398.5       ],
       [467.        , 371.        ],
       [487.        , 344.5       ],
       [508.        , 313.1984021 ],
       [528.        , 284.54197708],
       [546.        , 258.75119457],
       [567.        , 228.66194831],
       [587.        , 200.0055233 ]])
```

ì´ ê²°ê³¼ëŠ” rowì— ë”°ë¥¸ pixelì˜ outputì´ ë˜ê³  ì´ì œ ì´ yê°’ì„ `griding_num`ì— ë”°ë¼ ì¼ì •í•˜ê²Œ gridë¡œ ì˜ë¼ì„œ í•´ë‹¹ gridì— labelì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ classificationí•˜ëŠ” methodê°€ `_grid_pts` ê°€ ëœë‹¤

```python
    def _grid_pts(self, pts, num_cols, w):
        num_lane, n, n2 = pts.shape
        col_sample = np.linspace(0, w - 1, num_cols) # making column grids

        assert n2 == 2

        to_pts = np.zeros((n, num_lane)) # n is the number of row samples

        for i in range(num_lane):
            pti = pts[i, :, 1]  # ith lane x points
            interval = col_sample[1] - col_sample[0]
            to_pts[:,i] = np.asarray([int(pt // interval) if pt != -1 else num_cols for pt in pti])
        return to_pts.astype(int)
```

inputìœ¼ë¡œ lane points, # of columns(grid ê°œìˆ˜), image widthê°€ ëœë‹¤.

ê²°ë¡ ì ìœ¼ë¡œëŠ” ì´ ê²°ê³¼ëŠ”

```
cls_label
array([[200,  83,  97, 109],
       [200,  79, 101, 119],
       [200,  76, 105, 129],
       [200,  73, 108, 138],
       [200,  69, 112, 148],
       [200,  65, 116, 158],
       [200,  62, 120, 168],
       [200,  59, 123, 177],
       [200,  55, 127, 185],
       [200,  51, 131, 195],
       [200,  48, 134, 200],
       [200,  45, 138, 200],
       [200,  41, 142, 200],
       [200,  38, 146, 200],
       [200,  34, 149, 200],
       [200,  31, 153, 200],
       [200,  27, 157, 200],
       [200,  24, 160, 200]])
```

ì´ì™€ ê°™ì€ class labelì„ ë°˜í™˜í•œë‹¤

ê° ì—´ë§ˆë‹¤ í•´ë‹¹ laneìœ¼ë¡œ classificationëœê²Œ ìˆë‹¤ë©´ ê·¸ê²ƒì˜ grid indexê°’ì´ ì €ì¥ë˜ì–´ìˆê³  ë§Œì•½ì— ì—†ë‹¤ë©´ 200ì´ ì €ì¥ë˜ì–´ìˆë‹¤.

row anchor ê°œìˆ˜ê°€ 18ê°œì´ë¯€ë¡œ row ê°œìˆ˜ëŠ” 18ê°œì´ë‹¤.

ê·¸ë˜ì„œ ê·¸ ì´í›„ì— ë§Œì•½ `use_aux`ê°€ Trueì´ë©´ `seg_label`ê¹Œì§€ ë°˜í™˜í•´ì£¼ê³  í•˜ì—¬

```python
        if self.use_aux:
            assert self.segment_transform is not None
            seg_label = self.segment_transform(label)

        if self.img_transform is not None:
            img = self.img_transform(img)

        # return a tuple according to the provided flags.
        if self.use_aux:
            return img, cls_label, seg_label
        if self.load_name:
            return img, cls_label, img_name
        return img, cls_label

```

ìµœì¢…ì ìœ¼ë¡œ `img`, `cls_label`, `seg_label` ì´ë ‡ê²Œ ì´ë¯¸ì§€, class label, segmentation labelì„ ë°˜í™˜í•˜ê²Œ ëœë‹¤.

ì´ë ‡ê²Œí•˜ë©´

```python
# LaneClsDataset ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (auxiliary segmentation ì‚¬ìš©)
    dataset = LaneClsDataset(root_path=data_root,
                             list_path=list_path,
                             img_transform=img_transform,
                             target_transform=target_transform,
                             simu_transform=simu_transform,
                             row_anchor=culane_row_anchor,
                             griding_num=griding_num,
                             use_aux=True,
                             segment_transform=segment_transform,
                             num_lanes=4)

    # ë°ì´í„°ì…‹ì—ì„œ ì„ì˜ì˜ ìƒ˜í”Œ ì¸ë±ìŠ¤ ì„ íƒ (ì˜ˆ: 1000ë²ˆì§¸)
    try:
        img, cls_label, seg_label = dataset[1000]
    except IndexError:
        print("ìƒ˜í”Œ ì¸ë±ìŠ¤ 1000ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ í¬ê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        exit(1)

```

ì´ë ‡ê²Œ dataë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê²Œ ë˜ëŠ” ê²ƒì´ë©° ì´ê²ƒì´ pytorch Datasetì˜ ì—­í• ì´ ëœë‹¤.

ì´ë ‡ê²Œ ë°˜í™˜ëœ ì´ë¯¸ì§€ì™€ `cls_label`ê³¼ `seg_label`ì„ visualizeí•´ë³´ë©´

![](assets/img/culane_dataset_overlay.png)
*augmentationê³¼ ê·¸ì—ë”°ë¼ labelì´ ì˜ ovelayë˜ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.*

<details>
<summary> visualization code </summary>
<div markdown="block">

```python
def visualize_lane_labels(img, cls_label, seg_label, row_anchor, griding_num=200, w=800, alpha=0.5):
    """
    ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— cls_labelê³¼ seg_labelì„ í•¨ê»˜ ì‹œê°í™”í•©ë‹ˆë‹¤.

    Args:
        img: ì›ë³¸ ì´ë¯¸ì§€ (PIL Image ë˜ëŠ” tensor)
        cls_label: (n, num_lanes) í¬ê¸°ì˜ classification label í–‰ë ¬
        seg_label: segmentation mask (tensor ë˜ëŠ” numpy array)
        row_anchor: row ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸
        griding_num: grid ì—´ ê°œìˆ˜
        w: ì´ë¯¸ì§€ ë„ˆë¹„
        alpha: segmentation overlay íˆ¬ëª…ë„

    Returns:
        lane ë§ˆí‚¹ê³¼ segmentation overlayê°€ í¬í•¨ëœ ì‹œê°í™” ì´ë¯¸ì§€
    """
    import matplotlib.pyplot as plt
    import numpy as np
    import cv2
    from PIL import Image
    import torch

    # tensorì¸ ê²½ìš° numpyë¡œ ë³€í™˜ (ì •ê·œí™” í•´ì œ í¬í•¨)
    if isinstance(img, torch.Tensor):
        if img.shape[0] == 3 and img.max() <= 1:
            mean = torch.tensor().view(3, 1, 1)
            std = torch.tensor().view(3, 1, 1)
            img = img * std + mean
        img = img.permute(1, 2, 0).cpu().numpy()
        img = np.clip(img, 0, 1)
    elif isinstance(img, Image.Image):
        img = np.array(img) / 255.0

    vis_img = img.copy()
    h, w_img = vis_img.shape[:2]

    if isinstance(seg_label, torch.Tensor):
        seg_label = seg_label.cpu().numpy()

    seg_overlay = np.zeros_like(vis_img)
    seg_colors = [
        (0, 0, 0.7),    # Dark blue
        (0, 0.7, 0),    # Dark green
        (0.7, 0, 0),    # Dark red
        (0.7, 0.7, 0),  # Dark yellow
        (0.7, 0, 0.7),  # Dark magenta
        (0, 0.7, 0.7),  # Dark cyan
    ]

    # segmentation maskì˜ ì‚¬ì´ì¦ˆê°€ ë‹¤ë¥´ë©´ resize
    if len(seg_label.shape) == 2:
        seg_h, seg_w = seg_label.shape
        if seg_h != h or seg_w != w_img:
            seg_label = cv2.resize(seg_label.astype(np.float32), (w_img, h),
                                   interpolation=cv2.INTER_NEAREST).astype(seg_label.dtype)
    else:
        if len(seg_label.shape) == 3:
            c, seg_h, seg_w = seg_label.shape
            if seg_h != h or seg_w != w_img:
                resized_seg = np.zeros((c, h, w_img), dtype=seg_label.dtype)
                for i in range(c):
                    resized_seg[i] = cv2.resize(seg_label[i].astype(np.float32), (w_img, h),
                                                interpolation=cv2.INTER_NEAREST).astype(seg_label.dtype)
                seg_label = resized_seg

    # segmentation overlay ì±„ìš°ê¸°
    if len(seg_label.shape) == 2:
        for lane_class in range(1, int(seg_label.max()) + 1):
            mask = seg_label == lane_class
            color = seg_colors[(lane_class - 1) % len(seg_colors)]
            for c in range(3):
                seg_overlay[:, :, c][mask] = color[c]
    else:
        num_classes = seg_label.shape[0]
        for lane_class in range(1, num_classes):  # background ì œì™¸
            mask = seg_label[lane_class] > 0
            color = seg_colors[(lane_class - 1) % len(seg_colors)]
            for c in range(3):
                seg_overlay[:, :, c][mask] = color[c]

    vis_img_with_seg = cv2.addWeighted(vis_img, 1, seg_overlay, alpha, 0)

    cls_colors = [
        (0, 0, 1),    # Blue
        (0, 1, 0),    # Green
        (1, 0, 0),    # Red
        (1, 1, 0),    # Yellow
        (1, 0, 1),    # Magenta
        (0, 1, 1),    # Cyan
    ]
    col_sample = np.linspace(0, w - 1, griding_num)
    col_interval = col_sample[1] - col_sample[0]

    num_lanes = cls_label.shape[1]
    for lane_idx in range(num_lanes):
        color = cls_colors[lane_idx % len(cls_colors)]
        lane_points =
        for i, row in enumerate(row_anchor):
            col_idx = cls_label[i, lane_idx]
            if col_idx < griding_num:
                col_pos = col_idx * col_interval
                if h != 288:
                    row_pos = int(row * h / 288)
                else:
                    row_pos = row
                lane_points.append((int(col_pos), row_pos))
        for i in range(len(lane_points) - 1):
            cv2.line(vis_img_with_seg, lane_points[i], lane_points[i+1], color, thickness=2)
            cv2.circle(vis_img_with_seg, lane_points[i], radius=3, color=color, thickness=-1)
        if lane_points:
            cv2.circle(vis_img_with_seg, lane_points[-1], radius=3, color=color, thickness=-1)

    plt.figure(figsize=(12, 8))
    plt.imshow(vis_img_with_seg)
    plt.title("Lane Visualization with Segmentation")
    plt.axis('off')
    plt.show()

    return vis_img_with_seg

if __name__ == '__main__':
    import torchvision.transforms as transforms
    import data.mytransforms as mytransforms
    import matplotlib.pyplot as plt

    # DATA ê²½ë¡œ ë° íŒŒë¼ë¯¸í„° ì„¤ì • (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
    data_root = 'culane'
    list_path = os.path.join(data_root, "list/train_gt.txt")
    culane_row_anchor = [121, 131, 141, 150, 160, 170, 180, 189, 199, 209, 219, 228, 238, 248, 258, 267, 277, 287]
    griding_num = 200

    # ì´ë¯¸ì§€ ë° íƒ€ê²Ÿ ë³€í™˜ ì •ì˜
    img_transform = transforms.Compose([
        transforms.Resize((288, 800)),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    ])
    target_transform = transforms.Compose([
        mytransforms.FreeScaleMask((288, 800)),
        mytransforms.MaskToTensor()
    ])
    simu_transform = mytransforms.Compose2([
        mytransforms.RandomRotate(6),
        mytransforms.RandomUDoffsetLABEL(100),
        mytransforms.RandomLROffsetLABEL(200)
    ])
    segment_transform = transforms.Compose([
        mytransforms.FreeScaleMask((36, 100)),
        mytransforms.MaskToTensor()
    ])

    # LaneClsDataset ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (auxiliary segmentation ì‚¬ìš©)
    dataset = LaneClsDataset(root_path=data_root,
                             list_path=list_path,
                             img_transform=img_transform,
                             target_transform=target_transform,
                             simu_transform=simu_transform,
                             row_anchor=culane_row_anchor,
                             griding_num=griding_num,
                             use_aux=True,
                             segment_transform=segment_transform,
                             num_lanes=4)

    # ë°ì´í„°ì…‹ì—ì„œ ì„ì˜ì˜ ìƒ˜í”Œ ì¸ë±ìŠ¤ ì„ íƒ (ì˜ˆ: 1000ë²ˆì§¸)
    try:
        img, cls_label, seg_label = dataset[1000]
    except IndexError:
        print("ìƒ˜í”Œ ì¸ë±ìŠ¤ 1000ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ í¬ê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        exit(1)

    # ë¹„ì£¼ì–¼ë¼ì´ì œì´ì…˜ í•¨ìˆ˜ í˜¸ì¶œ
    visualize_lane_labels(img, cls_label, seg_label, culane_row_anchor, griding_num=griding_num)
```

</div>
</details>


ì´ë ‡ê²Œ culane datasetì„ í™œìš©í•˜ì—¬ ufldì—ì„œ ì–´ë–»ê²Œ Dataset utilì„ í†µí•´ dataë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ê°€ê³µí•˜ê³  ë°˜í™˜í•˜ê²Œ ë˜ëŠ”ì§€ ì•Œê²Œë˜ì—ˆë‹¤. 

ê¸€ì´ ê¸¸ì–´ì ¸ì„œ dataloaderëŠ” ë‹¤ìŒì— ì‘ì—…í•˜ë„ë¡í•˜ê³  ì•„ë˜ì— ë¬¸ì œë¥¼ í†µí•´ì„œ ë³µìŠµí•˜ê³  ê¸°ì–µí•  ìˆ˜ ìˆë„ë¡ 10ê°€ì§€ì˜ ë¬¸ì œë¥¼ ì ì–´ë³´ì•˜ë‹¤. 

> ì–´ë ¤ìš´ê²Œ ì•„ë‹ˆê³  ìµìˆ™í•˜ì§€ ì•Šì€ ê²ƒì´ë‹¤. ìê¾¸ë³´ê³  ë§Œë‚˜ê³  ì–˜ê¸°í•´ì„œ ì¹œí•´ì§€ì. ë”¥ëŸ¬ë‹ì€ ê·¸ëŸ´ ê°€ì¹˜ê°€ ìˆëŠ” ì¹œêµ¬ë‹ˆê¹Œ.
{: .prompt-tip }

---

## ë³µìŠµ ë¬¸ì œ

<details>
<summary> 1. íŒŒì´ì¬ì—ì„œ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í‚¤ì›Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”? </summary>
<div markdown="block">
ë‹µ: `class`
</div>
</details>

<details>
<summary> 2. íŒŒì´ì¬ì—ì„œ í´ë˜ìŠ¤ì˜ ìƒì„±ìë¥¼ ì •ì˜í•˜ëŠ” íŠ¹ë³„í•œ ë©”ì„œë“œ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”? </summary>
<div markdown="block">
ë‹µ: `__init__`
</div>
</details>

<details>
<summary> 3. ë‹¤ìŒ ì½”ë“œì˜ ì¶œë ¥ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
<div markdown="block">
```python
my_list = [1, 2, 3, 4, 5]
print(my_list[1:3])
```
</div>
</summary>
<div markdown="block">
ë‹µ: `[2, 3]`
</div>
</details>

<details>
<summary> 4. PyTorchì—ì„œ custom datasetì„ ë§Œë“¤ê¸° ìœ„í•´ ìƒì†í•´ì•¼ í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”? </summary>
<div markdown="block">
ë‹µ: `torch.utils.data.Dataset`
</div>
</details>

<details>
<summary> 5. custom dataset í´ë˜ìŠ¤ì—ì„œ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ë©”ì„œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”? </summary>
<div markdown="block">
ë‹µ: `__init__`, `__len__`, `__getitem__`
</div>
</details>

<details>
<summary> 6. CULane Datasetì˜ segmentation labelì—ì„œ ê° ì°¨ì„ ì€ ì–´ë–¤ ê°’ìœ¼ë¡œ í‘œí˜„ë˜ë‚˜ìš”? </summary>
<div markdown="block">
ë‹µ: 1ë¶€í„° 4ê¹Œì§€ì˜ ì •ìˆ˜ ê°’ (1, 2, 3, 4)
</div>
</details>

<details>
<summary> 7. UFLDì˜ `LaneClsDataset`ì—ì„œ ì´ë¯¸ì§€ ë†’ì´ê°€ 288ì´ ì•„ë‹Œ ê²½ìš°, `row_anchor` ê°’ë“¤ì€ ì–´ë–»ê²Œ ì¡°ì •ë˜ë‚˜ìš”? </summary>
<div markdown="block">
ë‹µ: ì´ë¯¸ì§€ ë†’ì´ì™€ 288ì˜ ë¹„ìœ¨ì— ë”°ë¼ ê° `row_anchor` ê°’ì— ê³±í•´ì ¸ ë³´ì •ë©ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 8. `LaneClsDataset`ì˜ `_get_index` ë©”ì„œë“œëŠ” segmentation labelì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì–´ë–¤ í˜•íƒœì˜ ì¶œë ¥ì„ ìƒì„±í•˜ë‚˜ìš”? </summary>
<div markdown="block">
ë‹µ: ê° ì°¨ì„ ë³„ë¡œ row anchor ìœ„ì¹˜ì—ì„œì˜ (row, xì¢Œí‘œ)ë¥¼ ë‹´ê³  ìˆëŠ” numpy ë°°ì—´ (shape: (num_lanes, len(row_anchor), 2))
</div>
</details>

<details>
<summary> 9. `LaneClsDataset`ì˜ `_grid_pts` ë©”ì„œë“œëŠ” ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”? </summary>
<div markdown="block">
ë‹µ: ì¶”ì¶œëœ ì°¨ì„  ì¢Œí‘œë“¤ì„ ì´ë¯¸ì§€ ë„ˆë¹„ì— ë”°ë¼ `griding_num`ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° row anchor ìœ„ì¹˜ì—ì„œ í•´ë‹¹ ì°¨ì„ ì´ ì†í•˜ëŠ” grid indexë¥¼ classification label í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 10. UFLD í•™ìŠµ ì‹œ auxiliary lossë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `LaneClsDataset`ì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ ë°˜í™˜ë˜ëŠ” ë°ì´í„°ëŠ” ë¬´ì—‡ì¸ê°€ìš”? </summary>
<div markdown="block">
ë‹µ: ì›ë³¸ segmentation labelì— `segment_transform`ì„ ì ìš©í•œ `seg_label`
</div>
</details>

<details>
<summary> 11. `np.where()[0]`ì—ì„œ `[0]`ì„ ë¶™ì´ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">
ğŸ’¡ ì •ë‹µ
`np.where`ëŠ” ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë‹´ì€ íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤. íŠœí”Œì˜ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì‹¤ì œ ì¸ë±ìŠ¤ ë°°ì—´ì´ë¯€ë¡œ, `[0]`ì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë°°ì—´ì— ì ‘ê·¼í•©ë‹ˆë‹¤.
ì˜ˆ) `(array([10, 11, 12]),)` â†’ `[0]`ìœ¼ë¡œ ì‹¤ì œ ì¸ë±ìŠ¤ ì ‘ê·¼
</div>
</details>

<details>
<summary> 12. `super()` í˜¸ì¶œì„ Python3 ìŠ¤íƒ€ì¼ë¡œ ê³ ì¹˜ì‹œì˜¤</summary>
<div markdown="block">
```python
super(LaneClsDataset, self).__init__()
```
ğŸ’¡ ì •ë‹µ
```python
super().__init__()
```
Python3ì—ì„œëŠ” í´ë˜ìŠ¤ëª…ê³¼ `self`ë¥¼ ìƒëµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 13. ë¼ì¸ extrapolationì— `polyfit`ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">
ğŸ’¡ ì •ë‹µ
íšŒì „ ë˜ëŠ” ì´ë™ ë“±ì˜ ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì¸í•´ ì°¨ì„ ì˜ í•˜ë‹¨ ì¼ë¶€ê°€ ì´ë¯¸ì§€ ê²½ê³„ ì™¸ë¶€ë¡œ ê°€ë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ, ë‚¨ì•„ìˆëŠ” ìƒë‹¨ ë¶€ë¶„ì˜ í¬ì¸íŠ¸ë¥¼ ì´ìš©í•˜ì—¬ ì§ì„ ì˜ ì¶”ì„¸ë¥¼ ì˜ˆì¸¡í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì°¨ì„ ì„ ì—°ì¥í•˜ê¸° ìœ„í•´ `polyfit`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 14. `cls_label`ì— 200ì´ ë“¤ì–´ê°€ëŠ” ê²½ìš°ëŠ” ì–¸ì œì¸ê°€ìš”?</summary>
<div markdown="block">
ğŸ’¡ ì •ë‹µ
í•´ë‹¹ row anchor ìœ„ì¹˜ì— ì°¨ì„ ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° (`_gt.txt`ì—ì„œ í•´ë‹¹ ì°¨ì„ ì˜ ì¡´ì¬ ìœ ë¬´ê°€ 0ìœ¼ë¡œ í‘œì‹œëœ ê²½ìš°) ë˜ëŠ” `_get_index()` í•¨ìˆ˜ì˜ ê²°ê³¼ë¡œ í•´ë‹¹ rowì˜ ëª¨ë“  í¬ì¸íŠ¸ê°€ -1ë¡œ ì²˜ë¦¬ëœ ê²½ìš°ì…ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 15. íŒŒì´ì¬ì—ì„œ í´ë˜ìŠ¤ ìƒì†ì€ ì–´ë–»ê²Œ êµ¬í˜„í•˜ë‚˜ìš”?</summary>
<div markdown="block">

í´ë˜ìŠ¤ ì •ì˜ ì‹œ ê´„í˜¸ ì•ˆì— ë¶€ëª¨ í´ë˜ìŠ¤ë¥¼ ëª…ì‹œí•˜ì—¬ ìƒì†ë°›ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:
```python
class ChildClass(ParentClass):
    pass
```
</div>
</details>

<details>
<summary> 16. íŒŒì¼ì„ ì½ì„ ë•Œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” Python ë‚´ì¥ í•¨ìˆ˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

`open()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—´ê³ , `read()` ë˜ëŠ” `readlines()` ë©”ì„œë“œë¡œ íŒŒì¼ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 17. PyTorchì˜ `torch.utils.data.Dataset`ì„ ìƒì†ë°›ì•„ custom datasetì„ ë§Œë“œëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

DataLoaderì™€ í˜¸í™˜ë˜ì–´ ë°°ì¹˜ ë‹¨ìœ„ì˜ ë°ì´í„° ë¡œë”©, ì…”í”Œë§, ë©€í‹°í”„ë¡œì„¸ì‹± ë“±ì„ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 18. `transforms.Compose`ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

ì—¬ëŸ¬ ê°œì˜ transform í•¨ìˆ˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ê°„ê²°í•˜ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 19. UFLDì—ì„œ segmentation label ëŒ€ì‹  lane anchor(ë˜ëŠ” grid ê¸°ë°˜ì˜ cls label)ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

segmentation ë°©ì‹ë³´ë‹¤ anchor ê¸°ë°˜ ë°©ì‹ì´ occlusion ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì°¨ì„ ì˜ í˜•íƒœì™€ ìœ„ì¹˜ ì •ë³´ë¥¼ ë” íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 20. `__getitem__` ë©”ì„œë“œê°€ ì¤‘ìš”í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

ê° ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ì „ì²˜ë¦¬í•˜ê³ , DataLoaderê°€ ë°°ì¹˜ë¡œ ë°ì´í„°ë¥¼ ê³µê¸‰í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 21. ì½”ë“œì—ì„œ `np.polyfit`ê³¼ `np.polyval` í•¨ìˆ˜ëŠ” ì–´ë–¤ ì—­í• ì„ ìˆ˜í–‰í•˜ë‚˜ìš”?</summary>
<div markdown="block">

`np.polyfit`ì€ ì£¼ì–´ì§„ ì ë“¤ë¡œë¶€í„° íšŒê·€ì‹ì„ êµ¬í•˜ê³ , `np.polyval`ì€ ì´ íšŒê·€ì‹ì„ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡ ê°’ì„ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 22. ë°ì´í„° augmentation ì‹œ ì´ë¯¸ì§€ì™€ labelì— ë™ì¼í•œ ë³€í™˜ì„ ì ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì˜ ì •í•©ì„±ì„ ìœ ì§€í•˜ì—¬, ë³€í™˜ í›„ì—ë„ ì˜¬ë°”ë¥¸ ëŒ€ì‘ ê´€ê³„ë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
</div>
</details>

<details>
<summary> 23. UFLDì—ì„œ auxiliary branchë¥¼ ì‚¬ìš©í•˜ëŠ” ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?</summary>
<div markdown="block">

auxiliary branchëŠ” ë³´ì¡°ì ì¸ segmentation taskë¥¼ ìˆ˜í–‰í•˜ì—¬ ë©”ì¸ branchì˜ í•™ìŠµì„ ë³´ì™„í•˜ê³ , ì „ì²´ ì°¨ì„  ê°ì§€ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
</div>
</details>
